{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9329bce2-da32-4cca-83ed-00f8534dbb0f",
   "metadata": {},
   "source": [
    "# 背景\n",
    "> * 预训练模型和语言模型是两个不同角度的概念：预训练模型一般指之前在某些任务上训练过的模型，是为了给初始化模型导入先验知识（优化参数的初始化）来加速模型在下游任务下的训练，或者说约束模型在下游任务的学习；语言模型是指给模型导入人类语言的先验知识，当前主要包括Masked language modeling（人类可以通过上下文推测出中间的某个文本的能力）和Causal language modeling（人类可以通过上文推测下文的能力），通过模拟人类的部分语言理解能力来使模型的理解能力尽量接近人类的理解能力，约束模型的参数化能力范围接近人类思考的范围，让模型像人一样思考（所以应该还有其他模型可以模仿的人类语言理解能力，所以人类可能只是半成品）\n",
    "> * 所以如果做下游任务，有一个对下游数据有一定了解或约束的语言模型作为预训练模型最后得到的效果会更好（迁移学习），所以如果有个预训练模型，它所了解的数据和你要做的任务数据差异很大，那需要我们微调这个预训练模型（例如，如果您的数据集包含法律合同或科学文章，像 BERT 这样的普通 Transformer 模型通常会将您的语料库中的特定领域词视为稀有标记，并且由此产生的性能可能不尽如人意。我们希望微调后，模型能够反映我们要做的数据的一些特点，通过mask或向后预测可以反映），称为domain adaptation 域适应，这个微调一般只做一次就行，只是让模型了解你要做的一些数据，所以训练得到的loss结果没有必要追求到极限，只要差不多就行\n",
    "> * 语言模型反馈人类本身对于语言的理解，所以只需要原始文本，任务信息通过下游任务添加\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "536375bf-84b2-4cea-9f75-9351b11c5435",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zyl/disk/poetry_env/algorithms-ai-IgVB5U1f-py3.10/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'\n",
    "os.environ[\"WANDB_MODE\"] = \"offline\"\n",
    "import transformers\n",
    "\n",
    "transformers.logging.set_verbosity_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e67056-99ad-4f61-8ffb-ae83d564c94f",
   "metadata": {},
   "source": [
    "# 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf7b8cb2-f7ff-432d-96c2-171bb41bc815",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration christykoh--imdb_pt-d17ce256d2a40640\n",
      "Found cached dataset parquet (/home/zyl/disk/algorithms_ai/algorithms_ai/learning/cache/christykoh___parquet/christykoh--imdb_pt-d17ce256d2a40640/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "imdb_dataset = load_dataset(path=\"christykoh/imdb_pt\",split='test',cache_dir='./cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aa69be6-da50-49f9-b622-1098e2559bc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset,validation_dataset = imdb_dataset.select(range(1000)).train_test_split(test_size=0.1).values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976c3a0a-170f-4dc4-9702-6920134998f5",
   "metadata": {},
   "source": [
    "# 指标\n",
    "> * perplexity(PPL)困惑度\n",
    "> * cross-entropy交叉熵"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed32db3d-6fb2-40de-877b-e251bc5c2f35",
   "metadata": {},
   "source": [
    "# Masked language modeling\n",
    "> * 掩码模型，主要通过遮掩出一段文本中的某些词（15%）,通过训练让模型能够推测遮掩的内容是什么\n",
    "> * 主要有bert结构\n",
    "> * 实际是token的预测，每个token的预测维度是vocab的大小，而且难以通过传统PPL来评估它，所以huggingface中用交叉熵来替代PPL\n",
    "> * 微调后的语言模型适应了新的数据集，并且不会忘掉它之前的预训练内容"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dc1247-89c7-4182-8c1d-65ac60f0779c",
   "metadata": {},
   "source": [
    "## 导入model和tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f66008c-ab45-45a0-af51-d23cc0556b4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/zyl/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/zyl/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForMaskedLM.\n",
      "\n",
      "All the weights of DistilBertForMaskedLM were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForMaskedLM\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "model = DistilBertForMaskedLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72a4ee81-a29b-4781-acc7-52d3cf6408fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForMaskedLM(\n",
       "  (activation): GELUActivation()\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (vocab_transform): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (vocab_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (vocab_projector): Linear(in_features=768, out_features=30522, bias=True)\n",
       "  (mlm_loss_fct): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12c3c315-3a1b-4fb5-8bf5-c619bc5ac527",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /home/zyl/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/zyl/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/zyl/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522e2bbf-faa5-47b7-860f-16780f99aa3e",
   "metadata": {},
   "source": [
    "##  把数据处理成模型能够接收的格式\n",
    "> * 最常见的做法是把每个文本作为一个样本进行输入处理，使用pad和truncation\n",
    "> * 但huggingface有种推荐做法：首先把所有文本tokenzizer成每个子输入，然后组成一段长输入，然后使用chunk进行切分成多个样本，最后多余的可以忽略或padding\n",
    "> * 注意这个chunk不能太小，最好参考下数据\n",
    "> * 对于最后余留的部分可以选择保留或填充或忽略---这部分的实现可以使用tokenizer中的return-overflowing-token=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7146452-7159-46ce-8cdf-9df02de1e613",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_data_for_language_model(examples, tokenizer, use_chunk=True,chunk_size=None,text_column='text',create_new_labels=True):\n",
    "    if use_chunk:\n",
    "        # 使用的时候因为使用chunk使得输入和输出的维度不一样，所以map中要remove_columns已有的列\n",
    "        # 先tokenizer\n",
    "        result = tokenizer(examples[text_column])\n",
    "        if tokenizer.is_fast:\n",
    "            result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "\n",
    "        # 再组合\n",
    "        if not chunk_size:\n",
    "            chunk_size=tokenizer.model_max_length\n",
    "        concatenated_examples = {k: sum(result[k], []) for k in result.keys()} # Concatenate all texts\n",
    "        total_length = len(concatenated_examples[list(result.keys())[0]])  # Compute length of concatenated texts\n",
    "        total_length = (total_length // chunk_size) * chunk_size #  We drop the last chunk if it's smaller than chunk_size\n",
    "        result = {\n",
    "            k: [t[i: i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "            for k, t in concatenated_examples.items()\n",
    "        }  # Split by chunks of max_len\n",
    "\n",
    "        if create_new_labels:\n",
    "            result[\"labels\"] = result[\"input_ids\"].copy() # Create a new labels column\n",
    "    else:\n",
    "        if chunk_size:\n",
    "            tokenizer.model_max_length = chunk_size\n",
    "        result = tokenizer(examples[text_column],truncation=True)\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9e74cca-6df8-4540-99d7-4a683692e2e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                         | 0/1 [00:00<?, ?ba/s]Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.70s/ba]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.99ba/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset = train_dataset.map(process_data_for_language_model,\n",
    "                                       fn_kwargs={\"tokenizer\": tokenizer, \"chunk_size\": 154,'use_chunk':True,'text_column':'text','create_new_labels':True},\n",
    "                                       batched=True, remove_columns=train_dataset.column_names)\n",
    "\n",
    "validation_dataset = validation_dataset.map(process_data_for_language_model,\n",
    "                                       fn_kwargs={\"tokenizer\": tokenizer, \"chunk_size\": 154,'use_chunk':True,'text_column':'text','create_new_labels':True},\n",
    "                                       batched=True, remove_columns=validation_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb1b7623-34df-4908-b68a-3223732619bd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [7367,\n",
       "  2226,\n",
       "  16095,\n",
       "  24110,\n",
       "  3527,\n",
       "  7367,\n",
       "  4372,\n",
       "  8663,\n",
       "  6494,\n",
       "  2213,\n",
       "  6846,\n",
       "  3672,\n",
       "  2063,\n",
       "  2053,\n",
       "  3309,\n",
       "  1025,\n",
       "  3449,\n",
       "  2050,\n",
       "  1041,\n",
       "  1037,\n",
       "  10026,\n",
       "  2063,\n",
       "  1041,\n",
       "  17540,\n",
       "  2890,\n",
       "  8529,\n",
       "  3595,\n",
       "  16843,\n",
       "  1013,\n",
       "  6187,\n",
       "  2229,\n",
       "  16137,\n",
       "  10841,\n",
       "  25226,\n",
       "  2015,\n",
       "  10861,\n",
       "  3449,\n",
       "  2063,\n",
       "  2087,\n",
       "  2527,\n",
       "  10861,\n",
       "  3449,\n",
       "  2063,\n",
       "  1041,\n",
       "  14736,\n",
       "  2015,\n",
       "  2188,\n",
       "  2213,\n",
       "  2079,\n",
       "  10861,\n",
       "  10514,\n",
       "  2050,\n",
       "  10026,\n",
       "  2063,\n",
       "  1010,\n",
       "  14163,\n",
       "  9956,\n",
       "  11498,\n",
       "  1051,\n",
       "  10975,\n",
       "  10936,\n",
       "  2121,\n",
       "  3972,\n",
       "  2050,\n",
       "  1012,\n",
       "  28681,\n",
       "  2891,\n",
       "  9808,\n",
       "  4958,\n",
       "  19565,\n",
       "  20617,\n",
       "  2015,\n",
       "  23310,\n",
       "  3286,\n",
       "  1037,\n",
       "  14163,\n",
       "  6590,\n",
       "  15287,\n",
       "  2480,\n",
       "  1041,\n",
       "  3348,\n",
       "  2080,\n",
       "  1012,\n",
       "  8823,\n",
       "  9808,\n",
       "  3595,\n",
       "  16843,\n",
       "  2015,\n",
       "  11265,\n",
       "  17811,\n",
       "  7509,\n",
       "  10938,\n",
       "  28118,\n",
       "  24110,\n",
       "  3527,\n",
       "  6366,\n",
       "  2213,\n",
       "  7367,\n",
       "  2271,\n",
       "  1051,\n",
       "  10841,\n",
       "  10483,\n",
       "  1041,\n",
       "  14017,\n",
       "  15464,\n",
       "  9808,\n",
       "  9298,\n",
       "  18349,\n",
       "  2015,\n",
       "  1012,\n",
       "  1037,\n",
       "  9353,\n",
       "  7113,\n",
       "  4424,\n",
       "  1041,\n",
       "  12990,\n",
       "  2063,\n",
       "  1010,\n",
       "  16137,\n",
       "  11498,\n",
       "  2771,\n",
       "  2213,\n",
       "  11968,\n",
       "  26005,\n",
       "  14163,\n",
       "  9956,\n",
       "  10424,\n",
       "  8625,\n",
       "  22723,\n",
       "  1041,\n",
       "  6904,\n",
       "  4877,\n",
       "  2050,\n",
       "  1012,\n",
       "  1051,\n",
       "  19817,\n",
       "  19736,\n",
       "  28061,\n",
       "  4830,\n",
       "  4950,\n",
       "  17214,\n",
       "  4783,\n",
       "  2213,\n",
       "  17491,\n",
       "  11610,\n",
       "  28774,\n",
       "  24664,\n",
       "  3406,\n",
       "  8529,\n",
       "  13433,\n",
       "  14194,\n",
       "  2080,\n",
       "  2139,\n",
       "  5549],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'word_ids': [172,\n",
       "  172,\n",
       "  173,\n",
       "  174,\n",
       "  174,\n",
       "  175,\n",
       "  176,\n",
       "  176,\n",
       "  176,\n",
       "  176,\n",
       "  177,\n",
       "  177,\n",
       "  177,\n",
       "  178,\n",
       "  179,\n",
       "  180,\n",
       "  181,\n",
       "  181,\n",
       "  182,\n",
       "  183,\n",
       "  184,\n",
       "  184,\n",
       "  185,\n",
       "  186,\n",
       "  186,\n",
       "  187,\n",
       "  188,\n",
       "  188,\n",
       "  189,\n",
       "  190,\n",
       "  190,\n",
       "  191,\n",
       "  191,\n",
       "  191,\n",
       "  191,\n",
       "  192,\n",
       "  193,\n",
       "  193,\n",
       "  194,\n",
       "  194,\n",
       "  195,\n",
       "  196,\n",
       "  196,\n",
       "  197,\n",
       "  198,\n",
       "  198,\n",
       "  199,\n",
       "  199,\n",
       "  200,\n",
       "  201,\n",
       "  202,\n",
       "  202,\n",
       "  203,\n",
       "  203,\n",
       "  204,\n",
       "  205,\n",
       "  205,\n",
       "  206,\n",
       "  207,\n",
       "  208,\n",
       "  208,\n",
       "  208,\n",
       "  209,\n",
       "  209,\n",
       "  210,\n",
       "  211,\n",
       "  211,\n",
       "  212,\n",
       "  213,\n",
       "  213,\n",
       "  213,\n",
       "  213,\n",
       "  214,\n",
       "  214,\n",
       "  215,\n",
       "  216,\n",
       "  216,\n",
       "  217,\n",
       "  217,\n",
       "  218,\n",
       "  219,\n",
       "  219,\n",
       "  220,\n",
       "  221,\n",
       "  222,\n",
       "  223,\n",
       "  223,\n",
       "  223,\n",
       "  224,\n",
       "  224,\n",
       "  225,\n",
       "  226,\n",
       "  226,\n",
       "  227,\n",
       "  227,\n",
       "  228,\n",
       "  228,\n",
       "  229,\n",
       "  229,\n",
       "  230,\n",
       "  230,\n",
       "  230,\n",
       "  231,\n",
       "  232,\n",
       "  232,\n",
       "  233,\n",
       "  234,\n",
       "  234,\n",
       "  234,\n",
       "  235,\n",
       "  236,\n",
       "  237,\n",
       "  237,\n",
       "  238,\n",
       "  239,\n",
       "  240,\n",
       "  240,\n",
       "  241,\n",
       "  242,\n",
       "  243,\n",
       "  244,\n",
       "  244,\n",
       "  245,\n",
       "  245,\n",
       "  246,\n",
       "  246,\n",
       "  247,\n",
       "  247,\n",
       "  247,\n",
       "  248,\n",
       "  249,\n",
       "  249,\n",
       "  249,\n",
       "  250,\n",
       "  251,\n",
       "  252,\n",
       "  252,\n",
       "  252,\n",
       "  253,\n",
       "  254,\n",
       "  255,\n",
       "  255,\n",
       "  255,\n",
       "  256,\n",
       "  256,\n",
       "  257,\n",
       "  258,\n",
       "  258,\n",
       "  259,\n",
       "  260,\n",
       "  260,\n",
       "  260,\n",
       "  261,\n",
       "  262],\n",
       " 'labels': [7367,\n",
       "  2226,\n",
       "  16095,\n",
       "  24110,\n",
       "  3527,\n",
       "  7367,\n",
       "  4372,\n",
       "  8663,\n",
       "  6494,\n",
       "  2213,\n",
       "  6846,\n",
       "  3672,\n",
       "  2063,\n",
       "  2053,\n",
       "  3309,\n",
       "  1025,\n",
       "  3449,\n",
       "  2050,\n",
       "  1041,\n",
       "  1037,\n",
       "  10026,\n",
       "  2063,\n",
       "  1041,\n",
       "  17540,\n",
       "  2890,\n",
       "  8529,\n",
       "  3595,\n",
       "  16843,\n",
       "  1013,\n",
       "  6187,\n",
       "  2229,\n",
       "  16137,\n",
       "  10841,\n",
       "  25226,\n",
       "  2015,\n",
       "  10861,\n",
       "  3449,\n",
       "  2063,\n",
       "  2087,\n",
       "  2527,\n",
       "  10861,\n",
       "  3449,\n",
       "  2063,\n",
       "  1041,\n",
       "  14736,\n",
       "  2015,\n",
       "  2188,\n",
       "  2213,\n",
       "  2079,\n",
       "  10861,\n",
       "  10514,\n",
       "  2050,\n",
       "  10026,\n",
       "  2063,\n",
       "  1010,\n",
       "  14163,\n",
       "  9956,\n",
       "  11498,\n",
       "  1051,\n",
       "  10975,\n",
       "  10936,\n",
       "  2121,\n",
       "  3972,\n",
       "  2050,\n",
       "  1012,\n",
       "  28681,\n",
       "  2891,\n",
       "  9808,\n",
       "  4958,\n",
       "  19565,\n",
       "  20617,\n",
       "  2015,\n",
       "  23310,\n",
       "  3286,\n",
       "  1037,\n",
       "  14163,\n",
       "  6590,\n",
       "  15287,\n",
       "  2480,\n",
       "  1041,\n",
       "  3348,\n",
       "  2080,\n",
       "  1012,\n",
       "  8823,\n",
       "  9808,\n",
       "  3595,\n",
       "  16843,\n",
       "  2015,\n",
       "  11265,\n",
       "  17811,\n",
       "  7509,\n",
       "  10938,\n",
       "  28118,\n",
       "  24110,\n",
       "  3527,\n",
       "  6366,\n",
       "  2213,\n",
       "  7367,\n",
       "  2271,\n",
       "  1051,\n",
       "  10841,\n",
       "  10483,\n",
       "  1041,\n",
       "  14017,\n",
       "  15464,\n",
       "  9808,\n",
       "  9298,\n",
       "  18349,\n",
       "  2015,\n",
       "  1012,\n",
       "  1037,\n",
       "  9353,\n",
       "  7113,\n",
       "  4424,\n",
       "  1041,\n",
       "  12990,\n",
       "  2063,\n",
       "  1010,\n",
       "  16137,\n",
       "  11498,\n",
       "  2771,\n",
       "  2213,\n",
       "  11968,\n",
       "  26005,\n",
       "  14163,\n",
       "  9956,\n",
       "  10424,\n",
       "  8625,\n",
       "  22723,\n",
       "  1041,\n",
       "  6904,\n",
       "  4877,\n",
       "  2050,\n",
       "  1012,\n",
       "  1051,\n",
       "  19817,\n",
       "  19736,\n",
       "  28061,\n",
       "  4830,\n",
       "  4950,\n",
       "  17214,\n",
       "  4783,\n",
       "  2213,\n",
       "  17491,\n",
       "  11610,\n",
       "  28774,\n",
       "  24664,\n",
       "  3406,\n",
       "  8529,\n",
       "  13433,\n",
       "  14194,\n",
       "  2080,\n",
       "  2139,\n",
       "  5549]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589f2f6a-8cc2-4813-9eeb-749f42808d39",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 数据打包并且mask\n",
    "> * 随机mask评估集会导致每次评估时测试的结果会有波动----其实还好，因为语言模型只是作为预训练模型，不需要达到顶级的精度，只要达到某个可以的值就行，所以最后只要看到loss波动平稳就行，\n",
    "> * 整个词的mask会比单个token的mask好吗？？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fd55b0-c83d-48a6-97fb-2639a44839de",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 整个词的mask\n",
    "# 如果您使用整个单词掩码整理器，您还需要进行设置remove_unused_columns=False以确保我们在训练期间不会丢失该word_ids列\n",
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "from transformers import default_data_collator\n",
    "\n",
    "wwm_probability = 0.2\n",
    "\n",
    "\n",
    "def whole_word_masking_data_collator(features):\n",
    "    for feature in features:\n",
    "        word_ids = feature.pop(\"word_ids\")\n",
    "\n",
    "        # Create a map between words and corresponding token indices\n",
    "        mapping = collections.defaultdict(list)\n",
    "        current_word_index = -100\n",
    "        current_word = None\n",
    "        for idx, word_id in enumerate(word_ids):\n",
    "            if word_id is not None:\n",
    "                if word_id != current_word:\n",
    "                    current_word = word_id\n",
    "                    current_word_index += 1\n",
    "                mapping[current_word_index].append(idx)\n",
    "\n",
    "        # Randomly mask words\n",
    "        mask = np.random.binomial(1, wwm_probability, (len(mapping),))\n",
    "        input_ids = feature[\"input_ids\"]\n",
    "        labels = feature[\"labels\"]\n",
    "        new_labels = [-100] * len(labels)\n",
    "        for word_id in np.where(mask)[0]:\n",
    "            word_id = word_id.item()\n",
    "            for idx in mapping[word_id]:\n",
    "                new_labels[idx] = labels[idx]\n",
    "                input_ids[idx] = tokenizer.mask_token_id\n",
    "        feature[\"labels\"] = new_labels\n",
    "\n",
    "    return default_data_collator(features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "181bfa84-63cc-4382-a716-a48d4c6a9ddb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 训练---随机屏蔽\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdd67d6-63ff-4587-9d07-a6ca594f7ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 固定mask，要额外使用dataloader\n",
    "def insert_random_mask(batch):\n",
    "    features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n",
    "    masked_inputs = data_collator(features)\n",
    "    # Create a new \"masked\" column for each column in the dataset\n",
    "    return {\"masked_\" + k: v.numpy() for k, v in masked_inputs.items()}\n",
    "\n",
    "downsampled_dataset = downsampled_dataset.remove_columns([\"word_ids\"])\n",
    "eval_dataset = downsampled_dataset[\"test\"].map(\n",
    "    insert_random_mask,\n",
    "    batched=True,\n",
    "    remove_columns=downsampled_dataset[\"test\"].column_names,\n",
    ")\n",
    "eval_dataset = eval_dataset.rename_columns(\n",
    "    {\n",
    "        \"masked_input_ids\": \"input_ids\",\n",
    "        \"masked_attention_mask\": \"attention_mask\",\n",
    "        \"masked_labels\": \"labels\",\n",
    "    }\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(\n",
    "    downsampled_dataset[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    eval_dataset, batch_size=batch_size, collate_fn=default_data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca21c599-2950-49b7-8bee-3bfa56aee3c4",
   "metadata": {},
   "source": [
    "## 评估和训练和评估\n",
    "> * 因为随机mask，可以看到每次结果都有波动，正常\n",
    "> * 模型训练完使用的evaluation是训练后的模型，而不是预训练模型，里面每轮训练结果都会更新trainer里面的self.model\n",
    "> * mask_lm实际是vocab-token-cls，所以计算损失用的是交叉熵损失，把指数-交叉熵损失作为困惑度\n",
    "> * 用来fp16进行加速，可以，影响不大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dd2e6a7-096c-41b1-8c51-cfdebe91c473",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 64\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(train_dataset) // batch_size\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_name}-finetuned-imdb\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    push_to_hub=False,\n",
    "    fp16=True,\n",
    "    logging_steps=logging_steps,\n",
    "    save_strategy='epoch'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37b0d483-9de7-44bc-a3df-eaab9588ccfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 281\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 281\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:138.00671736557376\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate()\n",
    "import math\n",
    "print(f'Perplexity:{math.exp(trainer.evaluate()[ \"eval_loss\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a3b8132-a962-45d4-9818-93af77da0ef9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zyl/disk/poetry_env/algorithms-ai-IgVB5U1f-py3.10/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2604\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 123\n",
      "  Number of trainable parameters = 66985530\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='123' max='123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [123/123 00:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.210100</td>\n",
       "      <td>3.760866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.713400</td>\n",
       "      <td>3.453746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.526400</td>\n",
       "      <td>3.355043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 281\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-imdb/checkpoint-41\n",
      "Configuration saved in distilbert-base-uncased-finetuned-imdb/checkpoint-41/config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-imdb/checkpoint-41/pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-imdb/checkpoint-41/tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-imdb/checkpoint-41/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 281\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-imdb/checkpoint-82\n",
      "Configuration saved in distilbert-base-uncased-finetuned-imdb/checkpoint-82/config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-imdb/checkpoint-82/pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-imdb/checkpoint-82/tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-imdb/checkpoint-82/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 281\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-imdb/checkpoint-123\n",
      "Configuration saved in distilbert-base-uncased-finetuned-imdb/checkpoint-123/config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-imdb/checkpoint-123/pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-imdb/checkpoint-123/tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-imdb/checkpoint-123/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=123, training_loss=3.8075278600056968, metrics={'train_runtime': 43.8907, 'train_samples_per_second': 177.988, 'train_steps_per_second': 2.802, 'total_flos': 311479362732384.0, 'train_loss': 3.8075278600056968, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23f01789-24b6-4be5-9b7b-e12cbb53a7a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 281\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 281\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:29.385910858779788\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate()\n",
    "print(f'Perplexity:{math.exp(trainer.evaluate()[ \"eval_loss\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2d7a3e-0a48-4a4a-85b8-9bb9e471930c",
   "metadata": {},
   "source": [
    "## 使用accelarate加速"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddfe2e9-ef2b-4c4f-bc29-ace481975343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")\n",
    "\n",
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 3\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import math\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        losses.append(accelerator.gather(loss.repeat(batch_size)))\n",
    "\n",
    "    losses = torch.cat(losses)\n",
    "    losses = losses[: len(eval_dataset)]\n",
    "    try:\n",
    "        perplexity = math.exp(torch.mean(losses))\n",
    "    except OverflowError:\n",
    "        perplexity = float(\"inf\")\n",
    "\n",
    "    print(f\">>> Epoch {epoch}: Perplexity: {perplexity}\")\n",
    "\n",
    "    # Save and upload\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "        repo.push_to_hub(\n",
    "            commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1835c69f-93d5-45f6-b059-1ffe2cc4b5f1",
   "metadata": {},
   "source": [
    "## 使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5be47884-208e-4328-a240-21545f1c0664",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/zyl/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/zyl/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/zyl/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForMaskedLM.\n",
      "\n",
      "All the weights of DistilBertForMaskedLM were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForMaskedLM for predictions without further training.\n",
      "loading configuration file config.json from cache at /home/zyl/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/zyl/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/vocab.txt\n",
      "loading file tokenizer.json from cache at /home/zyl/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/zyl/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/zyl/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.036511871963739395, 'token': 3066, 'token_str': 'deal', 'sequence': 'this is a great deal.'}, {'score': 0.02395874261856079, 'token': 3112, 'token_str': 'success', 'sequence': 'this is a great success.'}, {'score': 0.023744728416204453, 'token': 6172, 'token_str': 'adventure', 'sequence': 'this is a great adventure.'}, {'score': 0.01608501560986042, 'token': 2801, 'token_str': 'idea', 'sequence': 'this is a great idea.'}, {'score': 0.0108775170519948, 'token': 8658, 'token_str': 'feat', 'sequence': 'this is a great feat.'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "checkpoint = 'distilbert-base-uncased'\n",
    "# checkpoint = f\"{checkpoint.split(\"/\")[-1]}-finetuned-imdb\"\n",
    "\n",
    "mask_filler = pipeline(\n",
    "    \"fill-mask\", model=checkpoint\n",
    ")\n",
    "text = \"This is a great [MASK].\"\n",
    "preds = mask_filler(text)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2470fbe9-50ec-4199-b264-5fb128f4a0a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file distilbert-base-uncased-finetuned-imdb/checkpoint-123/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased-finetuned-imdb/checkpoint-123\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file distilbert-base-uncased-finetuned-imdb/checkpoint-123/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased-finetuned-imdb/checkpoint-123\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file distilbert-base-uncased-finetuned-imdb/checkpoint-123/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForMaskedLM.\n",
      "\n",
      "All the weights of DistilBertForMaskedLM were initialized from the model checkpoint at distilbert-base-uncased-finetuned-imdb/checkpoint-123.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForMaskedLM for predictions without further training.\n",
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.05909404158592224, 'token': 3066, 'token_str': 'deal', 'sequence': 'this is a great deal.'}, {'score': 0.033409856259822845, 'token': 6172, 'token_str': 'adventure', 'sequence': 'this is a great adventure.'}, {'score': 0.032685987651348114, 'token': 2801, 'token_str': 'idea', 'sequence': 'this is a great idea.'}, {'score': 0.016976814717054367, 'token': 3112, 'token_str': 'success', 'sequence': 'this is a great success.'}, {'score': 0.015000013634562492, 'token': 9467, 'token_str': 'shame', 'sequence': 'this is a great shame.'}]\n"
     ]
    }
   ],
   "source": [
    "checkpoint = 'distilbert-base-uncased'\n",
    "checkpoint = f\"{checkpoint.split('/')[-1]}-finetuned-imdb/checkpoint-123\"\n",
    "\n",
    "mask_filler = pipeline(\n",
    "    \"fill-mask\", model=checkpoint\n",
    ")\n",
    "text = \"This is a great [MASK].\"\n",
    "preds = mask_filler(text)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea020ffe-981d-4064-9ae5-3ce3f4531808",
   "metadata": {},
   "source": [
    "## 把语言模型应用于下游任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "644d6834-6bfb-4906-b7ad-5f7a39b1a1d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file distilbert-base-uncased-finetuned-imdb/checkpoint-123/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file distilbert-base-uncased-finetuned-imdb/checkpoint-123/pytorch_model.bin\n",
      "Some weights of the model checkpoint at distilbert-base-uncased-finetuned-imdb/checkpoint-123 were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased-finetuned-imdb/checkpoint-123 and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = 'distilbert-base-uncased'\n",
    "checkpoint = f\"{checkpoint.split('/')[-1]}-finetuned-imdb/checkpoint-123\"\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    checkpoint, \n",
    "    cache_dir=\"/large_files/5T/huggingface_cache/model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a449508-3881-4ea4-baf0-0e68eda48197",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21447b3f-49db-4219-86b2-ae76feda77ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> This is a great deal.'\n",
      "'>>> This is a great success.'\n",
      "'>>> This is a great adventure.'\n",
      "'>>> This is a great idea.'\n",
      "'>>> This is a great feat.'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "text = \"This is a great [MASK].\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "token_logits = model(**inputs).logits\n",
    "# Find the location of [MASK] and extract its logits\n",
    "mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "# Pick the [MASK] candidates with the highest logits\n",
    "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "\n",
    "for token in top_5_tokens:\n",
    "    print(f\"'>>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eb3891-d7df-41c6-9873-e28ea3764308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 冻结层\n",
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
